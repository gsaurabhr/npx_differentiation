{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will download the Neuropixels data using the Allen SDK,  \n",
    "and extract and save units metadata, spike times, behavioral data (running speed).  \n",
    "We also convolve the spike times with a Gaussian kernel to obtain firing rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Neuropixels Visual Coding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:28:31.557625Z",
     "iopub.status.busy": "2021-11-15T10:28:31.533557Z",
     "iopub.status.idle": "2021-11-15T10:28:39.667242Z",
     "shell.execute_reply": "2021-11-15T10:28:39.664671Z",
     "shell.execute_reply.started": "2021-11-15T10:28:31.534067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T06:42:31.148498Z",
     "iopub.status.busy": "2021-11-15T06:42:31.148202Z",
     "iopub.status.idle": "2021-11-15T06:42:31.151539Z",
     "shell.execute_reply": "2021-11-15T06:42:31.150909Z",
     "shell.execute_reply.started": "2021-11-15T06:42:31.148401Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_depths = {\n",
    "    'L1' : 100,\n",
    "    'L2/3' : 210,\n",
    "    'L4' : 120,\n",
    "    'L5' : 220,\n",
    "    'L6' : 200,\n",
    "}\n",
    "\n",
    "ctx_regions = ['VISp', 'VISl', 'VISrl', 'VISal', 'VISpm', 'VISam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T06:42:31.154865Z",
     "iopub.status.busy": "2021-11-15T06:42:31.154509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_directory = '/local1/data/tmp'# must be updated to a valid directory in your filesystem\n",
    "data_directory = '/allen/programs/braintv/workgroups/tiny-blue-dot/differentiation/refactor/data'\n",
    "\n",
    "manifest_path = path.join(src_directory, \"manifest.json\")\n",
    "cache = EcephysProjectCache.from_warehouse(manifest=manifest_path)\n",
    "sessions = cache.get_session_table()\n",
    "\n",
    "print('Total number of sessions: ' + str(len(sessions)))\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_sessions = sessions # [(sessions.full_genotype.str.find('wt/wt') > -1)]\n",
    "\n",
    "filtered_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T11:50:33.797225Z",
     "iopub.status.busy": "2021-10-18T11:50:33.796906Z",
     "iopub.status.idle": "2021-10-18T11:50:33.814994Z",
     "shell.execute_reply": "2021-10-18T11:50:33.814481Z",
     "shell.execute_reply.started": "2021-10-18T11:50:33.797198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # download filtered session data\n",
    "# \n",
    "# for session_index in tqdm(filtered_sessions.index.values):\n",
    "#     cache.get_session_data(\n",
    "#         session_index, isi_violations_maximum = np.inf,\n",
    "#         amplitude_cutoff_maximum = np.inf,\n",
    "#         presence_ratio_minimum = -np.inf\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read, reformat and export session-wise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T11:50:35.673986Z",
     "iopub.status.busy": "2021-10-18T11:50:35.673033Z",
     "iopub.status.idle": "2021-10-18T11:50:35.696054Z",
     "shell.execute_reply": "2021-10-18T11:50:35.695322Z",
     "shell.execute_reply.started": "2021-10-18T11:50:35.673875Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py # required for reading the nwb file\n",
    "\n",
    "attr_names = { # this is required because some attribute names changed from one nwb version to another\n",
    "    'id' : 'id',\n",
    "    'channel' : 'channel',\n",
    "    'snr' : 'snr',\n",
    "    'd_prime' : 'd_prime',\n",
    "    'isi_viol' : 'isi_viol',\n",
    "    'region' : 'ccf_structure',\n",
    "    'probe' : 'probe',\n",
    "    'hpos' : 'xpos_probe',\n",
    "    'vpos' : 'ypos_probe',\n",
    "}\n",
    "attr_names_alt = {\n",
    "    'channel' : 'peak_channel_id',\n",
    "    'isi_viol' : 'isi_violations',\n",
    "    'region' : 'id',\n",
    "    'probe' : 'id',\n",
    "    'hpos' : 'id',\n",
    "    'vpos' : 'id',\n",
    "}\n",
    "\n",
    "def _read_activity(src_file):\n",
    "    \"\"\"Read units, unit metadata and spiking rate data from source file\"\"\"\n",
    "    \n",
    "    units = pd.DataFrame()\n",
    "    spike_times = {}\n",
    "    \n",
    "    with h5py.File(src_file, mode='r') as sf:\n",
    "        if 'nwb_version' not in sf.keys(): # session_format nwb\n",
    "#             print('Old nwb version.')\n",
    "            attrs = [\n",
    "                'channel', 'id', 'snr', 'd_prime', 'isi_viol',\n",
    "                'region', 'probe', 'hpos', 'vpos'\n",
    "            ]\n",
    "            units = pd.DataFrame(columns=attrs)\n",
    "            for attr in attrs:\n",
    "                try:\n",
    "                    units[attr] = sf['units'][attr_names[attr]]\n",
    "                except KeyError:\n",
    "                    units[attr] = sf['units'][attr_names_alt[attr]]\n",
    "            units['RS'] = sf['units']['waveform_duration'][:]>0.4\n",
    "            grp_probe = sf['general/extracellular_ephys/electrodes']\n",
    "            cols = ['hpos', 'vpos', 'probe', 'region']\n",
    "            probes = pd.DataFrame(\n",
    "                index=grp_probe['id'][:],\n",
    "                columns=cols,\n",
    "            )\n",
    "            probes['hpos'] = grp_probe['probe_horizontal_position'][:]\n",
    "            probes['vpos'] = grp_probe['probe_vertical_position'][:]\n",
    "            probes['probe'] = grp_probe['probe_id'][:].astype(str)\n",
    "            probes['region'] = grp_probe['location'][:].astype(str)\n",
    "            df = probes.loc[units['channel'], cols]\n",
    "            df.index = units.index\n",
    "            units[cols] = df\n",
    "            \n",
    "            spi = sf['units/spike_times_index'][:]\n",
    "            sido = 0\n",
    "            stimes = sf['units/spike_times'][:]\n",
    "            for i in range(len(units.index)):\n",
    "                uid = units.index[i]\n",
    "                sid = spi[i]\n",
    "                spike_times[uid] = stimes[sido:sid]\n",
    "                sido = sid\n",
    "            \n",
    "            stims = sf['intervals/'].keys()\n",
    "            stim_table = []\n",
    "            for stim in stims:\n",
    "                if stim=='invalid_times':\n",
    "                    continue\n",
    "                start_times = sf[f'intervals/{stim}/start_time'][:]\n",
    "                stimulus_names = sf[f'intervals/{stim}/stimulus_name'][:]\n",
    "                try:\n",
    "                    stimulus_blocks = sf[f'intervals/{stim}/stimulus_block'][:]\n",
    "                except:\n",
    "                    stimulus_blocks = -np.ones(len(start_times))\n",
    "                st = pd.DataFrame(\n",
    "                    data=[start_times, stimulus_names, stimulus_blocks],\n",
    "                    index=['time', 'stimulus_name', 'block']\n",
    "                ).T\n",
    "                stim_table.append(st)\n",
    "            stim_table = pd.concat(stim_table).sort_values('time').reset_index(drop=True)\n",
    "            \n",
    "            running = pd.Series(\n",
    "                data=sf['processing/running/running_speed/data'][:],\n",
    "                index=sf['processing/running/running_speed_end_times/timestamps'][:],\n",
    "                name='running_speed'\n",
    "            ).rename_axis('times').reset_index()\n",
    "            \n",
    "            return units, spike_times, running, stim_table\n",
    "\n",
    "def get_firing_rates(\n",
    "    spike_times, sampling_rate=200,\n",
    "    win=np.exp(-(np.arange(11)-5)**2/4)\n",
    "):\n",
    "    maxtime = max([\n",
    "        st.max() if len(st)>0 else 0 for st in spike_times.values()\n",
    "    ]) + 1\n",
    "    n_units = len(spike_times)\n",
    "    data = np.zeros((\n",
    "        n_units, np.rint(maxtime*sampling_rate).astype(int)\n",
    "    ), dtype='uint8')\n",
    "    \n",
    "    for i, st in enumerate(spike_times.values()):\n",
    "        st_int = np.array(st*sampling_rate, dtype=int)\n",
    "#         st_int = st_int[st_int<maxtime-1]\n",
    "        fr = np.zeros(\n",
    "            np.rint(maxtime*sampling_rate).astype(int),\n",
    "            dtype='uint8'\n",
    "        )\n",
    "        fr[st_int] = 1\n",
    "        data[i] = (sampling_rate/win.sum()*np.convolve(\n",
    "            fr, win, mode='same'\n",
    "        )).astype('uint8')\n",
    "    return data, np.linspace(\n",
    "        0, maxtime,\n",
    "        np.rint(maxtime*sampling_rate).astype(int),\n",
    "        endpoint=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T11:50:47.930709Z",
     "iopub.status.busy": "2021-10-18T11:50:47.930029Z",
     "iopub.status.idle": "2021-10-18T12:02:03.117298Z",
     "shell.execute_reply": "2021-10-18T12:02:03.116782Z",
     "shell.execute_reply.started": "2021-10-18T11:50:47.930626Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1b40006b424d1b8da2febd4ac4ca27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for session_index in tqdm(filtered_sessions.index.values):\n",
    "    if path.exists(f'{data_directory}/fr_{session_index}.pkl'):\n",
    "        continue\n",
    "    source = path.join(src_directory, f'session_{session_index}', f'session_{session_index}.nwb')\n",
    "    units, spike_times, running, stim_table = _read_activity(source)\n",
    "    layers = units.groupby('region').apply(\n",
    "        lambda _df: assign_approx_layers(_df) if _df.name in ctx_regions else None\n",
    "    ).dropna().droplevel(0).rename('layer')\n",
    "    units = units.join(layers)\n",
    "    \n",
    "    fr, times = get_firing_rates(spike_times)\n",
    "    fr = pd.DataFrame(fr.T, index=times)\n",
    "    \n",
    "    units.to_pickle(\n",
    "        f'{data_directory}/units_{session_index}.pkl'\n",
    "    )\n",
    "    \n",
    "    running.to_pickle(\n",
    "        f'{data_directory}/running_{session_index}.pkl'\n",
    "    )\n",
    "    \n",
    "    stim_table.to_pickle(\n",
    "        f'{data_directory}/stimulus_{session_index}.pkl'\n",
    "    )\n",
    "    \n",
    "    fr.to_pickle(\n",
    "        f'{data_directory}/fr_{session_index}.pkl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T11:44:37.902869Z",
     "iopub.status.busy": "2021-10-18T11:44:37.901798Z",
     "iopub.status.idle": "2021-10-18T11:44:37.913245Z",
     "shell.execute_reply": "2021-10-18T11:44:37.912196Z",
     "shell.execute_reply.started": "2021-10-18T11:44:37.902743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_units(df, session=None):\n",
    "#     layers = df.groupby('ecephys_structure_acronym').apply(\n",
    "#         lambda _df: assign_approx_layers(_df) if _df.name in ctx_regions else None\n",
    "#     ).dropna().droplevel(0).rename('layer')\n",
    "#     df = df.join(layers)\n",
    "    \n",
    "#     ct = pd.cut(\n",
    "#         df.waveform_duration, bins=[0, 0.4, 100],\n",
    "#         right=False, include_lowest=True, labels=[False, True]\n",
    "#     ).rename('RS')\n",
    "#     df = df.join(ct.astype(bool))\n",
    "    \n",
    "#     df = df.rename({'ecephys_structure_acronym':'region'}, axis=1)\n",
    "#     if session is not None:\n",
    "#         df.to_pickle(f'{data_directory}/units_{session}.pkl')\n",
    "#         return 1\n",
    "#     return df\n",
    "\n",
    "# units = cache.get_units()\n",
    "# units.groupby('ecephys_session_id').apply(lambda df: process_units(df, df.name))\n",
    "\n",
    "# up = process_units(units[units.ecephys_session_id==session_index])\n",
    "# up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring a single-session dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T11:42:16.482531Z",
     "iopub.status.busy": "2021-10-18T11:42:16.481749Z",
     "iopub.status.idle": "2021-10-18T11:42:16.501129Z",
     "shell.execute_reply": "2021-10-18T11:42:16.500074Z",
     "shell.execute_reply.started": "2021-10-18T11:42:16.482466Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['devices', 'extracellular_ephys', 'institution', 'session_id', 'stimulus', 'subject']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{20,\n",
       " 40,\n",
       " 60,\n",
       " 80,\n",
       " 100,\n",
       " 120,\n",
       " 140,\n",
       " 160,\n",
       " 180,\n",
       " 200,\n",
       " 220,\n",
       " 240,\n",
       " 260,\n",
       " 280,\n",
       " 300,\n",
       " 320,\n",
       " 340,\n",
       " 360,\n",
       " 380,\n",
       " 400,\n",
       " 420,\n",
       " 440,\n",
       " 460,\n",
       " 480,\n",
       " 500,\n",
       " 520,\n",
       " 540,\n",
       " 560,\n",
       " 580,\n",
       " 600,\n",
       " 620,\n",
       " 640,\n",
       " 660,\n",
       " 680,\n",
       " 700,\n",
       " 720,\n",
       " 740,\n",
       " 760,\n",
       " 780,\n",
       " 800,\n",
       " 820,\n",
       " 840,\n",
       " 860,\n",
       " 880,\n",
       " 900,\n",
       " 920,\n",
       " 940,\n",
       " 960,\n",
       " 980,\n",
       " 1000,\n",
       " 1020,\n",
       " 1040,\n",
       " 1060,\n",
       " 1080,\n",
       " 1100,\n",
       " 1120,\n",
       " 1140,\n",
       " 1160,\n",
       " 1180,\n",
       " 1200,\n",
       " 1220,\n",
       " 1240,\n",
       " 1260,\n",
       " 1280,\n",
       " 1300,\n",
       " 1320,\n",
       " 1340,\n",
       " 1360,\n",
       " 1380,\n",
       " 1400,\n",
       " 1420,\n",
       " 1440,\n",
       " 1460,\n",
       " 1480,\n",
       " 1500,\n",
       " 1520,\n",
       " 1540,\n",
       " 1560,\n",
       " 1580,\n",
       " 1600,\n",
       " 1620,\n",
       " 1640,\n",
       " 1660,\n",
       " 1680,\n",
       " 1700,\n",
       " 1720,\n",
       " 1740,\n",
       " 1760,\n",
       " 1780,\n",
       " 1800,\n",
       " 1820,\n",
       " 1840,\n",
       " 1860,\n",
       " 1880,\n",
       " 1900,\n",
       " 1920,\n",
       " 1940,\n",
       " 1960,\n",
       " 1980,\n",
       " 2000,\n",
       " 2020,\n",
       " 2040,\n",
       " 2060,\n",
       " 2080,\n",
       " 2100,\n",
       " 2120,\n",
       " 2140,\n",
       " 2160,\n",
       " 2180,\n",
       " 2200,\n",
       " 2220,\n",
       " 2240,\n",
       " 2260,\n",
       " 2280,\n",
       " 2300,\n",
       " 2320,\n",
       " 2340,\n",
       " 2360,\n",
       " 2380,\n",
       " 2400,\n",
       " 2420,\n",
       " 2440,\n",
       " 2460,\n",
       " 2480,\n",
       " 2500,\n",
       " 2520,\n",
       " 2540,\n",
       " 2560,\n",
       " 2580,\n",
       " 2600,\n",
       " 2620,\n",
       " 2640,\n",
       " 2660,\n",
       " 2680,\n",
       " 2700,\n",
       " 2720,\n",
       " 2740,\n",
       " 2760,\n",
       " 2780,\n",
       " 2800,\n",
       " 2820,\n",
       " 2840,\n",
       " 2860,\n",
       " 2880,\n",
       " 2900,\n",
       " 2920,\n",
       " 2940,\n",
       " 2960,\n",
       " 2980,\n",
       " 3000,\n",
       " 3020,\n",
       " 3040,\n",
       " 3060,\n",
       " 3080,\n",
       " 3100,\n",
       " 3120,\n",
       " 3140,\n",
       " 3160,\n",
       " 3180,\n",
       " 3200,\n",
       " 3220,\n",
       " 3240,\n",
       " 3260,\n",
       " 3280,\n",
       " 3300,\n",
       " 3320,\n",
       " 3340,\n",
       " 3360,\n",
       " 3380,\n",
       " 3400,\n",
       " 3420,\n",
       " 3440,\n",
       " 3460,\n",
       " 3480,\n",
       " 3500,\n",
       " 3520,\n",
       " 3540,\n",
       " 3560,\n",
       " 3580,\n",
       " 3600,\n",
       " 3620,\n",
       " 3640,\n",
       " 3660,\n",
       " 3680,\n",
       " 3700,\n",
       " 3720,\n",
       " 3740,\n",
       " 3760,\n",
       " 3780,\n",
       " 3800,\n",
       " 3820,\n",
       " 3840}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File(source, mode='r') as sf:\n",
    "    display(sf['general'].keys())\n",
    "#     display(set(sf['general/extracellular_ephys/electrodes/probe_vertical_position'][:]))\n",
    "#     display(sf.keys())\n",
    "#     print('')\n",
    "#     display(sf['units'].keys())\n",
    "#     print('')\n",
    "#     display(sf['units/waveform_duration'][:])\n",
    "#     halfwidths = sf['units/waveform_duration'][:]\n",
    "#     print('')\n",
    "#     display(sf['units/peak_channel_id'][:])\n",
    "#     print('')\n",
    "#     display(sf['processing'].keys())\n",
    "#     print('')\n",
    "#     display(sf['processing/running'].keys())\n",
    "#     print('')\n",
    "#     display(sf['processing/running/running_speed/data'][:])\n",
    "#     print('')\n",
    "#     display(sf['processing/eye_tracking_rig_metadata/eye_tracking_rig_metadata'].keys())\n",
    "#     print('')\n",
    "#     display(sf['general'].keys())\n",
    "#     print('')\n",
    "#     display(sf['general/extracellular_ephys/electrodes'].keys())\n",
    "#     print('')\n",
    "#     display(sf['general/extracellular_ephys/electrodes/id'][:])\n",
    "#     print('')\n",
    "#     display(sf['general/extracellular_ephys/electrodes/location'][:])\n",
    "#     print('')\n",
    "#     display(sf['processing/stimulus/timestamps'].keys())\n",
    "#     print('')\n",
    "#     display(sf['intervals/'].keys())\n",
    "#     print('')\n",
    "#     display(sf['intervals/invalid_times'].keys())\n",
    "#     print('')\n",
    "#     display(sf['intervals/invalid_times/start_time'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Differentiation",
   "language": "python",
   "name": "differentiation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
